{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a stacked model. This constists of:\n",
    "LEVEL 0: Catboost, Random Forests, Linear Regressor, KNN, Ridge Regression, SVM, ElasticNet, XGMBoost\n",
    "LEVEL 1: Linear Regression (As the meta learning model) which uses the StackingRegressor to find the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn import preprocessing\n",
    "from numpy import mean\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress Warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv('final_train.csv')\n",
    "test = pd.read_csv('final_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix differing features\n",
    "train_objs_num = len(train)\n",
    "dataset = pd.concat(objs=[train, test], axis=0)\n",
    "dataset = pd.get_dummies(dataset)\n",
    "train = copy.copy(dataset[:train_objs_num])\n",
    "test = copy.copy(dataset[train_objs_num:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data\n",
    "print(\"Training set \", train.shape)\n",
    "print(\"Test set \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill remaining NA's with 0 and negatives with 0\n",
    "train.fillna(0, inplace=True)\n",
    "test.fillna(0, inplace=True)\n",
    "train[train < 0] = 0\n",
    "test[test < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID Column\n",
    "train.drop(['id'], axis=1, inplace=True)\n",
    "test.drop(['id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = train.revenue\n",
    "X = train.drop('revenue', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = train.sort_values('revenue', ascending=False)\n",
    "z['revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Top 50 Best Features\n",
    "number_of_features = 50\n",
    "best_features = SelectKBest(score_func=chi2, k=number_of_features)\n",
    "y = y.astype('int')\n",
    "fit = best_features.fit(X, y)\n",
    "df_scores = pd.DataFrame(fit.scores_)\n",
    "df_columns = pd.DataFrame(X.columns)\n",
    "feature_scores = pd.concat([df_columns, df_scores], axis=1)\n",
    "feature_scores.columns = ['Specs', 'Score']\n",
    "print(feature_scores.nlargest(number_of_features, 'Score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = feature_scores.nlargest(number_of_features, 'Score')['Specs'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[selected_features]\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Training: ', X_tr.shape)\n",
    "print('Validation: ', X_val.shape)\n",
    "print('Test: ', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prep to determine best alpha for some models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the alpha with best value (here we choose 0.001 for ridge regression)\n",
    "alphas = [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1,0.5, 1]\n",
    "for a in alphas:\n",
    "    model = Ridge(alpha=a, normalize=True).fit(X,y) \n",
    "    score = model.score(X, y)\n",
    "    pred_y = model.predict(X)\n",
    "    mse = mean_squared_error(y, pred_y) \n",
    "    print(\"Alpha:{0:.6f}, R2:{1:.3f}, MSE:{2:.2f}, RMSE:{3:.2f}\".format(a, score, mse, np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best alpha for elasticNet is 0.001\n",
    "for a in alphas:\n",
    "    model = ElasticNet(alpha=a, normalize=True).fit(X,y) \n",
    "    score = model.score(X, y)\n",
    "    pred_y = model.predict(X)\n",
    "    mse = mean_squared_error(y, pred_y) \n",
    "    print(\"Alpha:{0:.6f}, R2:{1:.3f}, MSE:{2:.2f}, RMSE:{3:.2f}\".format(a, score, mse, np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the stack\n",
    "def get_stack():\n",
    "    layer1 = list()\n",
    "    layer1.append(('cat_boost', CatBoostRegressor(loss_function='RMSE', logging_level='Silent', depth = 9, early_stopping_rounds = 200, iterations = 1000, eval_metric='RMSE', learning_rate = 0.01)))\n",
    "    layer1.append(('random_forests', RandomForestRegressor(n_estimators = 3000, max_depth = 9, criterion='mse')))\n",
    "    layer1.append(('linear_reg', LinearRegression()))\n",
    "    layer1.append(('knn', KNeighborsRegressor(n_neighbors=10, weights='distance', p=5)))\n",
    "    layer1.append(('ridge_reg', Ridge(alpha=a, normalize=True)))\n",
    "    layer1.append(('svr', SVR(kernel='rbf',C=2.0, epsilon=0.2, gamma='auto')))\n",
    "    layer1.append(('elastic_net', ElasticNet(alpha=a, normalize=True)))\n",
    "    layer1.append(('xgm', xgb.XGBRegressor()))\n",
    "    layer2 = list()\n",
    "    layer2.append(('random_forests2', RandomForestRegressor(n_estimators = 3000, max_depth = 9, criterion='mse')))\n",
    "    layer2.append(('decision_tree', DecisionTreeRegressor(min_samples_leaf=5, criterion='mse', max_depth=9)))\n",
    "    layer3 = StackingRegressor(estimators = layer2, final_estimator=LinearRegression(), cv=k)\n",
    "    model = StackingRegressor(estimators=layer1, final_estimator=layer3, cv=k)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with just models themselves without stacking\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    models['cat_boost'] = CatBoostRegressor(loss_function='RMSE', logging_level='Silent', depth = 9, early_stopping_rounds = 200, iterations = 1000, eval_metric='RMSE', learning_rate = 0.01)\n",
    "    models['random_forests'] = RandomForestRegressor(n_estimators = 3000, max_depth = 9, criterion='mse')\n",
    "    models['linear_reg'] = LinearRegression()\n",
    "    models['knn'] = KNeighborsRegressor(n_neighbors=10, weights='distance', p=5)\n",
    "    models['ridge_reg'] = Ridge(alpha=0.001, normalize=True)\n",
    "    models['svr'] = SVR(kernel='rbf',C=2.0, epsilon=0.2, gamma='auto')\n",
    "    models['elastic_net'] = ElasticNet(alpha=0.001, normalize=True)\n",
    "    models['xgm'] = xgb.XGBRegressor()\n",
    "#     models['stacked'] = get_stack()\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "def evaluate_model(model):\n",
    "    cv = KFold(n_splits = k, random_state = 10, shuffle=True)\n",
    "    scores = cross_val_score(model, X, y, scoring='neg_root_mean_squared_error', cv=cv, n_jobs=1, error_score='raise')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround to bug in CatBoostRegressor not having attribute n_features_in_\n",
    "class CatBoostRegressor(CatBoostRegressor):\n",
    "    def n_features_in_(self):\n",
    "        return self.get_feature_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround to bug in StackingRegressor not having attribute final_estimator_\n",
    "class StackingRegressor(StackingRegressor):\n",
    "    def final_estimator_(self):\n",
    "        return self.final_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show which model is better\n",
    "models = get_models()\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model)\n",
    "    results.append(-scores)\n",
    "    names.append(name)\n",
    "    print(\"SCORE OF {} === {}\".format(name, -mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots of all models\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.xlabel('Models', fontsize=12)\n",
    "plt.ylabel('RMSE', fontsize=12)\n",
    "plt.suptitle('Performance Of Different Models', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and predict stacked model\n",
    "stack = get_stack()\n",
    "stack.fit(X, y)\n",
    "predictions = stack.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission\n",
    "submission = pd.read_csv('Data/sample_submission.csv')\n",
    "submission['revenue'] = np.expm1(predictions)\n",
    "submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
