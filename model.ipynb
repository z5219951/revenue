{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a stacked model. This constists of:\n",
    "LEVEL 0: Catboost, Random Forests, Linear Regressor, KNN, Ridge Regression, SVM, ElasticNet, XGMBoost\n",
    "LEVEL 1: Linear Regression (As the meta learning model) which uses the StackingRegressor to find the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn import preprocessing\n",
    "from numpy import mean\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set  (3000, 3814)\n",
      "Test set  (4398, 5079)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train = pd.read_csv('final_train.csv')\n",
    "test = pd.read_csv('final_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix differing features\n",
    "train_objs_num = len(train)\n",
    "dataset = pd.concat(objs=[train, test], axis=0)\n",
    "dataset = pd.get_dummies(dataset)\n",
    "train = copy.copy(dataset[:train_objs_num])\n",
    "test = copy.copy(dataset[train_objs_num:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set  (3000, 7207)\n",
      "Test set  (4398, 7207)\n"
     ]
    }
   ],
   "source": [
    "# Check data\n",
    "print(\"Training set \", train.shape)\n",
    "print(\"Test set \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill remaining NA's with 0 and negatives with 0\n",
    "train.fillna(0, inplace=True)\n",
    "test.fillna(0, inplace=True)\n",
    "train[train < 0] = 0\n",
    "test[test < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID Column\n",
    "train.drop(['id'], axis=1, inplace=True)\n",
    "test.drop(['id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = train.revenue\n",
    "X = train.drop('revenue', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1126    21.141685\n",
       "1761    21.132889\n",
       "2770    21.063590\n",
       "684     20.956666\n",
       "2322    20.839934\n",
       "          ...    \n",
       "695      0.693147\n",
       "1917     0.000000\n",
       "1874     0.000000\n",
       "1754     0.000000\n",
       "347      0.000000\n",
       "Name: revenue, Length: 3000, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = train.sort_values('revenue', ascending=False)\n",
    "z['revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Specs         Score\n",
      "3810                                         cast_score  2.757711e+13\n",
      "3811                                         crew_score  2.646228e+11\n",
      "0                                                budget  4.390390e+03\n",
      "3                                       name_collection  1.631334e+03\n",
      "3809                                     keywords_count  1.354816e+03\n",
      "2644        prodc_Québec Production Services Tax Credit  9.990000e+02\n",
      "2645                    prodc_Abu Dhabi Film Commission  9.990000e+02\n",
      "2646  prodc_Colorado Office of Film, Television & Media  9.990000e+02\n",
      "1160                         prodc_Chongoing Film Group  7.490000e+02\n",
      "1161                       prodc_Bon Voyage Film Studio  7.490000e+02\n",
      "1162                         prodc_Shanghai Media Group  7.490000e+02\n",
      "1163      prodc_Zhejiang Films & TV(Group) Company Ltd.  7.490000e+02\n",
      "1164                    prodc_Hunan Broadcasting System  7.490000e+02\n",
      "1165                     prodc_Anhui Broadcasting Corp.  7.490000e+02\n",
      "1166                           prodc_Beijing TV Station  7.490000e+02\n",
      "1858                      prodc_Centerstage Productions  7.490000e+02\n",
      "1859  prodc_Film Development Council of the Philippines  7.490000e+02\n",
      "2810                      prodc_Percept Picture Company  7.490000e+02\n",
      "4                                            budget_log  6.005727e+02\n",
      "1682                            prodc_People Tree Films  5.990000e+02\n",
      "2636                   prodc_Comet Film Produktion GmbH  5.990000e+02\n",
      "2637                                 prodc_Avrora Media  5.990000e+02\n",
      "2638                         prodc_Cobblestone Pictures  5.990000e+02\n",
      "2784             prodc_An Erich von Stroheim Production  5.990000e+02\n",
      "397                                prodc_China Film Co.  5.823994e+02\n",
      "140                                prodc_Marvel Studios  5.549769e+02\n",
      "963                    prodc_Media Rights Capital (MRC)  5.044655e+02\n",
      "578                                prodc_One Race Films  5.010992e+02\n",
      "1416                     prodc_Pitchblack Pictures Inc.  4.990000e+02\n",
      "1417                          prodc_Lighthouse Pictures  4.990000e+02\n",
      "1418                        prodc_Caliber Media Company  4.990000e+02\n",
      "1419  prodc_Motion Picture Corporation of America (M...  4.990000e+02\n",
      "1876                              prodc_Kim Ki-Duk Film  4.990000e+02\n",
      "1911                           prodc_KODA Entertainment  4.990000e+02\n",
      "2004                       prodc_Kingsize Entertainment  4.990000e+02\n",
      "3407                                     prodc_id films  4.990000e+02\n",
      "3408                                    prodc_leo films  4.990000e+02\n",
      "1                                            popularity  4.366321e+02\n",
      "1258                                prodc_Type 55 Films  4.275714e+02\n",
      "1900                                prodc_Vertigo Films  4.275714e+02\n",
      "2135                         prodc_Filmation Associates  4.275714e+02\n",
      "2181                                   prodc_Dharamsala  4.275714e+02\n",
      "2278                                  prodc_Pandemonium  4.275714e+02\n",
      "2279                    prodc_Lightstream Entertainment  4.275714e+02\n",
      "2301                                    prodc_iFeatures  4.275714e+02\n",
      "2302                           prodc_Sixty Six Pictures  4.275714e+02\n",
      "2303                               prodc_Oldgarth Media  4.275714e+02\n",
      "2456                      prodc_Кинокомпания «Lunapark»  4.275714e+02\n",
      "2457                                 prodc_Инвада фильм  4.275714e+02\n",
      "2930                     prodc_ABS-CBN Film Productions  4.275714e+02\n"
     ]
    }
   ],
   "source": [
    "# Select Top 50 Best Features\n",
    "number_of_features = 50\n",
    "best_features = SelectKBest(score_func=chi2, k=number_of_features)\n",
    "y = y.astype('int')\n",
    "fit = best_features.fit(X, y)\n",
    "df_scores = pd.DataFrame(fit.scores_)\n",
    "df_columns = pd.DataFrame(X.columns)\n",
    "feature_scores = pd.concat([df_columns, df_scores], axis=1)\n",
    "feature_scores.columns = ['Specs', 'Score']\n",
    "print(feature_scores.nlargest(number_of_features, 'Score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = feature_scores.nlargest(number_of_features, 'Score')['Specs'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cast_score</th>\n",
       "      <th>crew_score</th>\n",
       "      <th>budget</th>\n",
       "      <th>name_collection</th>\n",
       "      <th>keywords_count</th>\n",
       "      <th>prodc_Québec Production Services Tax Credit</th>\n",
       "      <th>prodc_Abu Dhabi Film Commission</th>\n",
       "      <th>prodc_Colorado Office of Film, Television &amp; Media</th>\n",
       "      <th>prodc_Chongoing Film Group</th>\n",
       "      <th>prodc_Bon Voyage Film Studio</th>\n",
       "      <th>...</th>\n",
       "      <th>prodc_Filmation Associates</th>\n",
       "      <th>prodc_Dharamsala</th>\n",
       "      <th>prodc_Pandemonium</th>\n",
       "      <th>prodc_Lightstream Entertainment</th>\n",
       "      <th>prodc_iFeatures</th>\n",
       "      <th>prodc_Sixty Six Pictures</th>\n",
       "      <th>prodc_Oldgarth Media</th>\n",
       "      <th>prodc_Кинокомпания «Lunapark»</th>\n",
       "      <th>prodc_Инвада фильм</th>\n",
       "      <th>prodc_ABS-CBN Film Productions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.000000e+03</td>\n",
       "      <td>3.000000e+03</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.142649e+09</td>\n",
       "      <td>7.631087e+07</td>\n",
       "      <td>11.959606</td>\n",
       "      <td>1.026360</td>\n",
       "      <td>7.226667</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.300792e+09</td>\n",
       "      <td>9.321631e+07</td>\n",
       "      <td>7.405678</td>\n",
       "      <td>2.088409</td>\n",
       "      <td>6.665891</td>\n",
       "      <td>0.018257</td>\n",
       "      <td>0.018257</td>\n",
       "      <td>0.018257</td>\n",
       "      <td>0.018257</td>\n",
       "      <td>0.018257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018257</td>\n",
       "      <td>0.018257</td>\n",
       "      <td>0.018257</td>\n",
       "      <td>0.018257</td>\n",
       "      <td>0.018257</td>\n",
       "      <td>0.018257</td>\n",
       "      <td>0.018257</td>\n",
       "      <td>0.018257</td>\n",
       "      <td>0.018257</td>\n",
       "      <td>0.018257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.280491e+08</td>\n",
       "      <td>1.509986e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.560853e+08</td>\n",
       "      <td>5.059708e+07</td>\n",
       "      <td>15.894952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.892482e+09</td>\n",
       "      <td>1.018539e+08</td>\n",
       "      <td>17.216708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.817312e+11</td>\n",
       "      <td>9.253127e+08</td>\n",
       "      <td>19.755682</td>\n",
       "      <td>6.045005</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cast_score    crew_score       budget  name_collection  \\\n",
       "count  3.000000e+03  3.000000e+03  3000.000000      3000.000000   \n",
       "mean   2.142649e+09  7.631087e+07    11.959606         1.026360   \n",
       "std    6.300792e+09  9.321631e+07     7.405678         2.088409   \n",
       "min    0.000000e+00  0.000000e+00     0.000000         0.000000   \n",
       "25%    3.280491e+08  1.509986e+07     0.000000         0.000000   \n",
       "50%    8.560853e+08  5.059708e+07    15.894952         0.000000   \n",
       "75%    1.892482e+09  1.018539e+08    17.216708         0.000000   \n",
       "max    1.817312e+11  9.253127e+08    19.755682         6.045005   \n",
       "\n",
       "       keywords_count  prodc_Québec Production Services Tax Credit  \\\n",
       "count     3000.000000                                  3000.000000   \n",
       "mean         7.226667                                     0.000333   \n",
       "std          6.665891                                     0.018257   \n",
       "min          0.000000                                     0.000000   \n",
       "25%          3.000000                                     0.000000   \n",
       "50%          6.000000                                     0.000000   \n",
       "75%         10.000000                                     0.000000   \n",
       "max        149.000000                                     1.000000   \n",
       "\n",
       "       prodc_Abu Dhabi Film Commission  \\\n",
       "count                      3000.000000   \n",
       "mean                          0.000333   \n",
       "std                           0.018257   \n",
       "min                           0.000000   \n",
       "25%                           0.000000   \n",
       "50%                           0.000000   \n",
       "75%                           0.000000   \n",
       "max                           1.000000   \n",
       "\n",
       "       prodc_Colorado Office of Film, Television & Media  \\\n",
       "count                                        3000.000000   \n",
       "mean                                            0.000333   \n",
       "std                                             0.018257   \n",
       "min                                             0.000000   \n",
       "25%                                             0.000000   \n",
       "50%                                             0.000000   \n",
       "75%                                             0.000000   \n",
       "max                                             1.000000   \n",
       "\n",
       "       prodc_Chongoing Film Group  prodc_Bon Voyage Film Studio  ...  \\\n",
       "count                 3000.000000                   3000.000000  ...   \n",
       "mean                     0.000333                      0.000333  ...   \n",
       "std                      0.018257                      0.018257  ...   \n",
       "min                      0.000000                      0.000000  ...   \n",
       "25%                      0.000000                      0.000000  ...   \n",
       "50%                      0.000000                      0.000000  ...   \n",
       "75%                      0.000000                      0.000000  ...   \n",
       "max                      1.000000                      1.000000  ...   \n",
       "\n",
       "       prodc_Filmation Associates  prodc_Dharamsala  prodc_Pandemonium  \\\n",
       "count                 3000.000000       3000.000000        3000.000000   \n",
       "mean                     0.000333          0.000333           0.000333   \n",
       "std                      0.018257          0.018257           0.018257   \n",
       "min                      0.000000          0.000000           0.000000   \n",
       "25%                      0.000000          0.000000           0.000000   \n",
       "50%                      0.000000          0.000000           0.000000   \n",
       "75%                      0.000000          0.000000           0.000000   \n",
       "max                      1.000000          1.000000           1.000000   \n",
       "\n",
       "       prodc_Lightstream Entertainment  prodc_iFeatures  \\\n",
       "count                      3000.000000      3000.000000   \n",
       "mean                          0.000333         0.000333   \n",
       "std                           0.018257         0.018257   \n",
       "min                           0.000000         0.000000   \n",
       "25%                           0.000000         0.000000   \n",
       "50%                           0.000000         0.000000   \n",
       "75%                           0.000000         0.000000   \n",
       "max                           1.000000         1.000000   \n",
       "\n",
       "       prodc_Sixty Six Pictures  prodc_Oldgarth Media  \\\n",
       "count               3000.000000           3000.000000   \n",
       "mean                   0.000333              0.000333   \n",
       "std                    0.018257              0.018257   \n",
       "min                    0.000000              0.000000   \n",
       "25%                    0.000000              0.000000   \n",
       "50%                    0.000000              0.000000   \n",
       "75%                    0.000000              0.000000   \n",
       "max                    1.000000              1.000000   \n",
       "\n",
       "       prodc_Кинокомпания «Lunapark»  prodc_Инвада фильм  \\\n",
       "count                    3000.000000         3000.000000   \n",
       "mean                        0.000333            0.000333   \n",
       "std                         0.018257            0.018257   \n",
       "min                         0.000000            0.000000   \n",
       "25%                         0.000000            0.000000   \n",
       "50%                         0.000000            0.000000   \n",
       "75%                         0.000000            0.000000   \n",
       "max                         1.000000            1.000000   \n",
       "\n",
       "       prodc_ABS-CBN Film Productions  \n",
       "count                     3000.000000  \n",
       "mean                         0.000333  \n",
       "std                          0.018257  \n",
       "min                          0.000000  \n",
       "25%                          0.000000  \n",
       "50%                          0.000000  \n",
       "75%                          0.000000  \n",
       "max                          1.000000  \n",
       "\n",
       "[8 rows x 50 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X[selected_features]\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (2400, 50)\n",
      "Validation:  (600, 50)\n",
      "Test:  (4398, 50)\n"
     ]
    }
   ],
   "source": [
    "print('Training: ', X_tr.shape)\n",
    "print('Validation: ', X_val.shape)\n",
    "print('Test: ', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prep to determine best alpha for some models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:0.000001, R2:0.565, MSE:4.05, RMSE:2.01\n",
      "Alpha:0.000010, R2:0.565, MSE:4.05, RMSE:2.01\n",
      "Alpha:0.000100, R2:0.565, MSE:4.05, RMSE:2.01\n",
      "Alpha:0.001000, R2:0.564, MSE:4.05, RMSE:2.01\n",
      "Alpha:0.010000, R2:0.555, MSE:4.14, RMSE:2.03\n",
      "Alpha:0.100000, R2:0.544, MSE:4.24, RMSE:2.06\n",
      "Alpha:0.500000, R2:0.517, MSE:4.49, RMSE:2.12\n",
      "Alpha:1.000000, R2:0.484, MSE:4.79, RMSE:2.19\n"
     ]
    }
   ],
   "source": [
    "# Find the alpha with best value (here we choose 0.001 for ridge regression)\n",
    "alphas = [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1,0.5, 1]\n",
    "for a in alphas:\n",
    "    model = Ridge(alpha=a, normalize=True).fit(X,y) \n",
    "    score = model.score(X, y)\n",
    "    pred_y = model.predict(X)\n",
    "    mse = mean_squared_error(y, pred_y) \n",
    "    print(\"Alpha:{0:.6f}, R2:{1:.3f}, MSE:{2:.2f}, RMSE:{3:.2f}\".format(a, score, mse, np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timluo1/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 644.4830549619037, tolerance: 2.789147700000007\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:0.000001, R2:0.563, MSE:4.06, RMSE:2.01\n",
      "Alpha:0.000010, R2:0.553, MSE:4.16, RMSE:2.04\n",
      "Alpha:0.000100, R2:0.540, MSE:4.28, RMSE:2.07\n",
      "Alpha:0.001000, R2:0.446, MSE:5.15, RMSE:2.27\n",
      "Alpha:0.010000, R2:0.113, MSE:8.25, RMSE:2.87\n",
      "Alpha:0.100000, R2:0.000, MSE:9.30, RMSE:3.05\n",
      "Alpha:0.500000, R2:0.000, MSE:9.30, RMSE:3.05\n",
      "Alpha:1.000000, R2:0.000, MSE:9.30, RMSE:3.05\n"
     ]
    }
   ],
   "source": [
    "# Best alpha for elasticNet is 0.001\n",
    "for a in alphas:\n",
    "    model = ElasticNet(alpha=a, normalize=True).fit(X,y) \n",
    "    score = model.score(X, y)\n",
    "    pred_y = model.predict(X)\n",
    "    mse = mean_squared_error(y, pred_y) \n",
    "    print(\"Alpha:{0:.6f}, R2:{1:.3f}, MSE:{2:.2f}, RMSE:{3:.2f}\".format(a, score, mse, np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the stack\n",
    "def get_stack():\n",
    "    layer1 = list()\n",
    "    layer1.append(('cat_boost', CatBoostRegressor(loss_function='RMSE', logging_level='Silent', depth = 9, early_stopping_rounds = 200, iterations = 1000, eval_metric='RMSE', learning_rate = 0.01)))\n",
    "    layer1.append(('random_forests', RandomForestRegressor(n_estimators = 3000, max_depth = 9, criterion='mse')))\n",
    "    layer1.append(('linear_reg', LinearRegression()))\n",
    "    layer1.append(('knn', KNeighborsRegressor(n_neighbors=10, weights='distance', p=5)))\n",
    "    layer1.append(('ridge_reg', Ridge(alpha=a, normalize=True)))\n",
    "    layer1.append(('svr', SVR(kernel='rbf',C=2.0, epsilon=0.2, gamma='auto')))\n",
    "    layer1.append(('elastic_net', ElasticNet(alpha=a, normalize=True)))\n",
    "    layer1.append(('xgm', xgb.XGBRegressor()))\n",
    "    layer2 = list()\n",
    "    layer2.append(('random_forests2', RandomForestRegressor(n_estimators = 3000, max_depth = 9, criterion='mse')))\n",
    "    layer2.append(('decision_tree', DecisionTreeRegressor(min_samples_leaf=5, criterion='mse', max_depth=9)))\n",
    "    layer3 = StackingRegressor(estimators = layer2, final_estimator=LinearRegression(), cv=k)\n",
    "    model = StackingRegressor(estimators=layer1, final_estimator=layer3, cv=k)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with just models themselves without stacking\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    models['cat_boost'] = CatBoostRegressor(loss_function='RMSE', logging_level='Silent', depth = 9, early_stopping_rounds = 200, iterations = 1000, eval_metric='RMSE', learning_rate = 0.01)\n",
    "    models['random_forests'] = RandomForestRegressor(n_estimators = 3000, max_depth = 9, criterion='mse')\n",
    "    models['linear_reg'] = LinearRegression()\n",
    "    models['knn'] = KNeighborsRegressor(n_neighbors=10, weights='distance', p=5)\n",
    "    models['ridge_reg'] = Ridge(alpha=0.001, normalize=True)\n",
    "    models['svr'] = SVR(kernel='rbf',C=2.0, epsilon=0.2, gamma='auto')\n",
    "    models['elastic_net'] = ElasticNet(alpha=0.001, normalize=True)\n",
    "    models['xgm'] = xgb.XGBRegressor()\n",
    "    models['stacked'] = get_stack()\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "def evaluate_model(model):\n",
    "    cv = KFold(n_splits = k, random_state = 10, shuffle=True)\n",
    "    scores = cross_val_score(model, X, y, scoring='neg_root_mean_squared_error', cv=cv, n_jobs=1, error_score='raise')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround to bug in CatBoostRegressor not having attribute n_features_in_\n",
    "class CatBoostRegressor(CatBoostRegressor):\n",
    "    def n_features_in_(self):\n",
    "        return self.get_feature_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround to bug in StackingRegressor not having attribute final_estimator_\n",
    "class StackingRegressor(StackingRegressor):\n",
    "    def final_estimator_(self):\n",
    "        return self.final_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show which model is better\n",
    "models = get_models()\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model)\n",
    "    results.append(-scores)\n",
    "    names.append(name)\n",
    "    print(\"SCORE OF {} === {}\".format(name, -mean(scores)))\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots of all models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and predict stacked model\n",
    "stack = get_stack()\n",
    "stack.fit(X, y)\n",
    "predictions = stack.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission\n",
    "# submission = pd.read_csv('Data/sample_submission.csv')\n",
    "# submission['revenue'] = np.expm1(predictions)\n",
    "# submission.to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
